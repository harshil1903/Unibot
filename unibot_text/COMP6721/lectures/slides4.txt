
= P(A)    x P(B) (by independence)
A+C
grow from there. By 2020, it is estimated that 1.7MB of data will be created every
Ham
…
ether_and_B_togcount_of_A
15
• for DTs: pruning level
 In real life:
Slide 72
Remember…
3. Apply learning algorithm to training set to learn the parameters
nb of instances that the
X1  X1 
yes)YoungyeseP(Toothach
6
 Sum Rule
defined class
Slide 29
Standard Methodology
yes) Youngyes hacheyes | TootP(Cavity
(that should have
new email 2 1 0 1 1 2 ?
 A simple probabilistic classifier based on Bayes' theorem
 gives confidence in its class predictions (i.e., the scores)
17
Parameters:
Getting the Probabilities
Slide 30
Association Rule Mining
ii
Example 2
1. TRAIN:
 Ex. with 16 binary variables, we would need 216 entries
 P(the|COOKING) =    P(the|SPORTS) =
51
Popular
Ex. Application: Spam Filtering
 So
 H1: weather will be nice P(H1) = 0.2

Example
 i.e. infer new knowledge from observed evidence
 ex: out of all people who have red spots… how many have meningitis?
60.05/3)noPlayTennis|sunnyOut(P
P(A1, A2, A3, A4, ..., An)
64
person
 value = number of times that word appears in the e-mail
Day2 Sunny Hot High Strong No
smoothing,
:Rule Bayes with
high school students
X500  X500  X500  X500 
 Times, the probability that C occurs, assuming that A and B have
yes)P(spots
ML is widely used in Data Mining
 predict the weather that maximizes the probability
 there are 28x28 = 784 features
 when one class is more important than the others
n
2. TEST:
Machine Learning Process
Day9 Sunny Cool Normal Weak Yes
Day11 Sunny Mild Normal Strong Yes
Slide 4
Why Machine Learning?
 With n events, we can generalize to the Chain rule:
evidence
67
 P(A,B) = P(A) x P(B)
a3.
yes) P(Youngyes) eP(Toothach
Image Classification
• for ANNs: weights
X4  X4  X4  X4 
 so if a text contains the word "dumbo", the class SPAM is
Reinforcement Learning
B)P(A,
Slide 62
4.05/2)noPlayTennis|rainOut(P
used to set up the ML model. eg.
 Training – Unsmoothed  / Smoothed  probs:
Slide 31

13
)H|P(E x )P(H  argmax  E)|P(H argmax  H ii
)H|P(E x )P(H argmax
Slide 28
 should it be classified as HAM or SPAM?
 If A and B are independent, then:
Slide 57
 P(Cavity | Young) = 0.18
Naive Bayes Classification

 then P("dumbo"| SPAM) = 0
)P(E
48
Metrics
Toothache ~Toothache
Recall=
 P(A|B) = 0.8 P(rain today| cloudy) = 0.8
 ∑i P(Ai) = 1 ⇒ one of the events Ai will take place
model labelled as class C
 P(A) = 1 ⇒ the event A must take place
no)yyes| CavitP(Youngno)yyes| CaviteP(Toothachno)P(Cavity
po
A BA∩B
model. eg.
Supervised
conditionally independent
yes )Youngyes ) x P(eP(Toothach
temp
Slide 46
yes)ityyes)xP(Cavyes|CavityYoungyeseP(Toothach
39
1j
cannot change our belief about A
Slide 12
independent given C:
 ex: log(0.01) + log(0.02) + log(0.05) + …
56
 that is often incorrect
doc1:  "cheap meds for sale"
Conditional Independent Events
 Question: how will be the weather tomorrow?
 ex: out of all people who have the meningitis … how many have red
 P(ball|COOKING) =       P(ball|SPORTS) =
second for every person on earth.
 P(meningitis=yes) = 0.00003
email 2 1 1 0 5 4 3 HAM
instance is NOT in class C C D
events A1,...,An takes place
Type of data Labelled data Unlabelled data No pre-defined data
Supervised
 Image processing: P(face_person | image features)
 Rolling two dice (together):
Slide 51
 feature = actual words in the e-mail
tasks T and performance measure P if its
)H|P(E x )P(H  )H|P(E x )P(H )H|P(E x )P(H  )P(E 3232221212
Day Outlook Temperature Humidity Wind Play Tennis
• for NB: value of delta for
 when one class C is more important than the others
19
Learning
4
nb of instances that
Association Clustering
 Assume now 2 pieces of evidence:
 28 x 28 grayscale images
Target system 1 system 2 system 3
 H2: weather will be bad P(H2) = 0.5

X500  X500 
)H|a(P ij
Conditional Probability (con’t)
 So we choose the Hi with the largest P(Hi|E)
40
 Given that C is true, then any evidence about B
64.014/9)yesPlayTennis(P
Spam
Slide 16
22
B)P(A,  A)|P(B 
Slide 25
COMP 6721
 N sets of training texts (1 set for each class)
12
 some variables are not independent…
identified as class C
The machine is trained
Combining Evidence
doc75000:   goal… injury …
 E1: today, there's a beautiful sunset
Independent Events
33.09/3)yesPlayTennis|strongWind(P
Slide 10
 with strong (naive) independence assumption
 P(A,B) = P(A|B) x P(B) (by chain rule)
 e1 = <sunset:beautiful, clouds:no, temp:high, summer:yes>
i2i
Day14 Rain Mild High Strong No
Logistic Regression, KNN,
 ex: Text Categorization (spam filtering)
 But how do we get the data ?
X4  X4 
)H|P(E x )P(H
occurrence of the other
vocabulary of size c in words of number total
→ Worksheet #3 (“Machine Learning System Evaluation”)
 Score(SPORTS)= log() + log(P(the|SPORTS)) + log(P(referee|SPORTS)) +
P(Ex|Hi) E1 E2 E3
All instances that
?
Be Careful: Use Logs
been assigned)
C4 0 1 3 94 2 0  100
for all classes ci   // ex. ham or spam
 what is P(Cavity | Toothache ∩ Young) ?
Slide 17
 so often represented as a feature/attribute vector
 P(A) = 0 ⇒ the event A will never take place
category.
X5  X5 
correct class
Slide 56
is
X3  X3 
→ If you have spots… you are more likely to have
)H(P estimate i
 ex: customer email  order, complaint, support request, ...→
yes)  Youngyes cheno| ToothaP(Cavity
Slide 65
 P(Cause | Side Effect)… P(misaligned brakes| squeaky wheels)
• for DTs: features to split
Slide 43
ML outside of AI
?yes)Youngyescheyes|ToothaP(Cavity 
 How do you know if what you learned is correct?
basic values learned by the ML
 we soon have numerical underflow…
 BUT:
 Prior (or unconditional) probability
42
correctly?
 Split data set into 3 sub-sets
 Where did the learner go wrong ?
90% !
Types of Machine Learning
A1,...,An take place
 Spam filter: P(spam_message | words in e-mail)
p(w1|c1) p(w2|c1) p(w3|c1) p(w4|c1) p(w5|c1) p(w6|c1)
iji
Example 3
yes)ityyes)xP(Cavyyes| CavitYoungyeseP(Toothach
doc5:   "here is the book for you"
 is the same for all possible Hi  (and is hard to gather anyways)
Slide 27
of the 10 classes
 Suppose, we know that
performance at tasks in T, as measured by
 A patient complains about Toothache and is Young…
 Naïve Bayes: Assumes that the attributes/features are
Slide 9
41
smaller pieces…
69
Strictly speaking, what we will see is called a Multinomial Naïve Bayes
discover output
digits from the American Census
 With 2 events, the probability that A and B occur is:
log(P(hit|COOKING)) + log(P(the|COOKING))
Hyper-parameters:  parameters
 H3: weather will be mixed P(H3) = 0.3
Postal Code Recognition
 You run your classifier on a data set of unseen examples (that
and rewards
2
55
Day12 Overcast Mild High Strong Yes
30
 basis of many spam filters
X2  X2 
25
 doc6:  “the cheap book”
you did not use for training) for which you know the correct
possible combinations of variables
 what if we have a P(wi|cj) = 0…?
21
Machine Learning
yes)vityyes)x P(Cayes|CavityYoungyes )  xP(yes|CavityeP(Toothach
Be Careful: Smooth Probabilities
 if the occurrence of one of them does not influence the
 E2: today, there's a average sunset
• for ANNs: nb of hidden layers, nb
 Diagnostic systems: P(Disease | Symptoms)
 e1 = <a1, … , an>
61
 argmaxcj log(P(cj)) + Σ log(P(wi|c))
26
COOKiNG SPORTS
Follow trail and error
doc2:   … the… referee… player…

33.09/3)yesPlayTennis|rainOut(P
 Probability of an event before any evidence is
Slide 24
Slide 7
 problem:
→ Worksheet #3 (“Joint Probabilities”)
 Assume we have 3 hypothesis...

Day8 Sunny Mild High Weak No
 ex: sports, recreation, politics, war, economy,…
P(Toothache ∩ Cavity ∩ Young)
1
score(ci) = score(ci) x P(wj | ci)
C5 0 0 3 2 92 3  100
 ex: living in Montreal & wearing boots
So?
 Recall: What proportion of the instances in class C are labelled
email 3 0 3 2 1 0 1 SPAM
email 1 3 2 5 1 0 1 SPAM
Slide 40
Slide 38
Slide 21
2. Naïve Bayes Classifier
without any guidance
argmaxH
for all classes ci // ex. ham or spam
 each feature = 256 greyscale value
Slide 39
= 99%
Slide 61
yes yes yes?  or no?
)H|P(a x )P(H argmax  )H|a,...,a,a,aP( x )P(H argmax)H|P(E x )P(H argmax
Day7 Overcast Cool Normal Strong Yes
45
...
18
Accuracy
 |V| = 100     vocabulary = {ball, heat, kitchen, referee, stove, the, ... }
 c2: HAM


 Goal: Given a new instance X=<a1,…, an>, classify as Yes/No
 so instead, we add the log of the probs
In reality, the instance is…
Slide 66
prior probabilities P(Hi)
36
Conditional Probability
P(E2 |H1)
:assumption ceindependen with
Machine Learning History
05.0
Example 1
using labelled data
feature so:
Slide 34
Bayes’ Reasoning
Training External supervision No supervision No supervision
 Out of n hypothesis…
71
X7  X7 
C1 C2 C3 C4 C5 C6 … Total
 to solve this: we assume that every word always appears at

 i.e.  A is independent of B if P(A) = P(A|B)
Slide 19
~Cavity 0.016 0.064 0.144 0.576
Algorithms
H
10
 when all classes are equally important and represented
Application of Bayesian Reasoning
 Probability of an event given that you know that B is
)c|P(w
Slide 15
method
 some variables are independent…
no][yes,H
Day3 Overcast Hot High Weak Yes
 Each set is already tagged by the class name
are in  class C and that
Slide 69
environment)
 denoted P(A∩B) or P(A,B)
…
word accident given the class SPORTS
e1 beautiful no high yes  Nice
)noPlayTennis(P )2
Day6 Rain Cool Normal Strong No
7
(task-driven)
)c in mentscount(docu
 Makes a strong assumption of conditional independence
 each e-mail in the training set is tagged with the correct
0.31  .12  .15  .04  .3x.4 .5x.3  .2x.2
doc3:  "book your trip"
 Joint probability distribution:
spots
 P(A)  = 0.1 P(rain today) = 0.1
 i.e. the features/attributes are conditionally independent
1. Collect a large set of examples (all with correct classifications)
)H|P(E x )P(H argmaxH ii
 Fast, easy to apply
attributes/features
66
sunset
 Predict the weather tomorrow based on tonight‘s sunset...
)H|P(X x )P(H  argmaxH
meningitis than if we don’t know about you having
…
 ex: 0.01 x 0.02 x 0.05 x …
 we want to find the most probable Hi given the evidence E
Slide 64
Cavity 0.04 0.06
using binary values for the presence/absence of words…
 75,000 docs in Sports

 in most applications, you just count from a set of
:assumption ceindependen lconditiona with
iii
that events are independent
Representing the Evidence
class C
yes)Youngyes ) x P(eP(Toothach
etc
classify the new case: X=(Outlook: Sunny, Temp: Cool, Hum: High, Wind: Strong)
 normally:
 fast, simple
 And 1 piece of evidence with 3 possible values
• for NB: prior & conditional
Slide 36
Slide 54
 Task: classify e-mails (documents) into a pre-
Slide 33
P, improves with experience E.”
(learns by reacting to
 Question:
0206.0
)c,count(w
5
activities.
 But Naïve Bayes works very well in many applications
Unsupervised Learning
Understand patterns and
0053.0
52
C2 0 93 3 4 0 0  100
Slide 11
00003.04.0
nb of instances that are in
Slide 52
H3 0.4 0.4 0.2
P(A)
H2 0.3 0.3 0.4
 ex. the word "dumbo" never appeared in the class SPAM?
 given:
Slide 63
Digit Recognition
2. Divide collection into training, validation and test set
the measles
 then:
Classification Regression
C6 0 0 5 0 10 85  100
yes)yyes| CavitP(Youngyes)yyes| CaviteP(Toothachyes)P(Cavity
ll_Bcount_of_a
ij
29
 often used as a baseline algorithm before trying other methods
for all classes ci
Slide 18
observations
compute
= P (∩Ai)

X5  X5  X5  X5 
Slide 5

= P(A1) × P(A2|A1) × P(A3|A1,A2) × ... × P(An|A1,A2,A3,…,An-1)
 …
)noPlayTennis|strongWind(xP)noPlayTennis|highHum(xP)noPlayTennis|coolTemp(xP)noPlayTennis|sunnyOutlook(P x
)H|a(P estimate ij
 Speech recognition: P(words | acoustic signal)
 c1: SPAM
 eg. when data set is unbalanced  Target system 1
 This e-mail is most likely spam
1st estimate the probabilities from the training examples:

 P(stove|COOKING) =    P(stove|SPORTS) =

 Rolling two dice one after the other, first dice rolled 1:
 These 2 pictures are very likely of the same
So what?
no)X(PlayTennis:answer 
A∩B
 P(Montreal, boots) ≠ P(Montreal) * P(boots)
 E3: today, there's no sunset
Slide 32
)P(Evidence
doc2:  "click here for the best meds"
 Score(COOKING)= log() + log(P(the|COOKING)) + log(P(referee|COOKING)) +
60
)yesPlayTennis|strongWind(xP)yesPlayTennis|highHum(xP)yesPlayTennis|coolTemp(xP)yesPlayTennis|sunnyOutlook(P x
 I can’t read this character, but it looks like a “B”
 P(Cavity | Toothache) = 0.12
Bayes’ Theorem
2. Validation set (~20%)
offer money viagra laptop exam study category
documents) count(all
50
 when all classes are equally important and represented
Example 4 evidence
Loop:
Reward Based
C3 0 1 94 2 1 2  100
tomorrow
X2  X2  X2  X2 
C1 94 3 0 0 3 0  100
hy
)c|P(w 
Supervised Learning
Reinforcement
Motivation
Day13 Overcast Hot Normal Weak Yes
Linear Regression,
 However P(Evidence | Hypothesis) is easier to gather
j
Bureau employees and American
16
P(B) x B)|P(A  B)P(A,  so
b) For each attribute value aj  of each instance (evidence)
46
score(ci) = P(ci)
 argmaxcj P(cj) P P(wi|cj)
68
in class C Is not in class C
Slide 50

doc1:   … stove… kitchen… the… heat
// 2. testing a new document D

 if we really do the product of probabilities…
65
 In reality, we may have dozens, hundreds of variables
Assume we only have 1 hypothesis
 Given
completely ruled out !
Slide 1
Types of problems Regression &Classification Association & Clustering Reward based
Slide 49
11
actions & discovers errors
for all words wj in the D
 Recall, Precision & F-measure
is)P(Hypothes)Hypothesis|P(Evidence
31
 beautiful sunset? clouds? temperature? summer?, …
count_of_AP(A) 
 Dataset
59
 surprisingly very effective on real-world tasks
ji c in words of number total
 P(heat|COOKING) =    P(heat|SPORTS) =
58
 probability of 2 heads in a row:
43
X1  X1  X1  X1 
3
Unsupervised
yes)isP(meningit x yes)meningitis|yesP(spots
Cavity 0.108 0.012 0.072 0.008
 Observation: average sunset (E2)
 0 ≤ P(A) ≤ 1
Learning
 Two events A and B are conditionally
2i 
 So Bayesian reasoning:

compute
P(A|B) x P(B) = P(B|A) x P(A)
“A computer program is said to learn from
Evidence)|isP(Hypothes
Definition The machine learns by
 i.e. Your belief about A given that you have no
 a.k.a. Knowledge Discovery in Databases (KDD)
~Cavity 0.01 0.89
classifies
…  … …  … 
 500,000 words in Cooking
choose c* = with the greatest score(ci)
Accuracy                        = 495/500
ll_eventscount_of_a
 task: correctly tag a new e-mail
a1
)H|P(a x )P(H  argmax
 P(kitchen|COOKING) =    P(kitchen|SPORTS) =
Comments on Naïve Bayes Classification
Types of ML Problems
 Text classification: P(sports_news | text)
of nodes per layer…
Slide 2
experience E with respect to some class of
Young ~ Young Young ~ Young
62
 The probability that A occurs
B)P(AB)|P(A 
Day1 Sunny Hot High Weak No
 ex: the word ambulance is not conditionally independent of the
classification
Accuracy  450/500 =
 Features: each pixel is used as a
 P(Hi | E2) ?
 P(A) + P(~A) = 1
Slide 22
P(E)
(data analytics)
Slide 68
Slide 44
Error Analysis


14
Artificial Intelligence:
Slide 71
probabilities
P(B)
occurred
classes assigned by the learner
 To make things work in real applications, we often assume
 Testing: “the referee hit the blue bird”
28
In 1959, Arthur Samuel first proposed
 Use a confusion matrix / contingency table
8
c2 : HAM
Model says…
https://en.wikipedia.org/wiki/MNIST_database
Another Application:
44
A
 With 3 events, the probability that A, B and C occur is:
Naive Bayes Classifier
environment by producing
 test set: 10,000 examples.
)H|P(E x )P(H  )E|P(H
Day4 Rain Mild High Weak Yes
not hold…
Slide 47
 300,000 words in Sports
in321i
 % of instances of the test set the algorithm correctly
Now we have decomposed the joint probability distribution into much
Accuracy  450/500 = 90% ! 498/500 = 99.6% 498/500 = 99.6%
ji
 denoted P(A ∪ B) = P(A) + P(B) - P(A ∩ B)
Approach Map labelled input to
true       (B = some evidence)
 MNIST dataset
 % of instances of the test set the algorithm correctly
instance is in class C A B
Slide 59
Slide 58
B)P(A,  B)|P(A 
offer money viagra laptop exam study category
c1 : SPAM
1. Actual training set (~80%)
data
K-means, C-means, etc Q-learning, etc
Slide 20
 P(COOKING) = P(SPORTS) =
P(A) x A)|P(B  B)P(A,  so
toothache young cavity

Chain Rule
doc2:   … kitchen… pasta… stove…
 Posterior (or conditional) probability
 i.e. Your belief about A given that you know B
summer
classifier, because we will count the number of words, as opposed to just
32
https://medium.com/machine-learning-for-humans/neural-networks-deep-learning-cdad8aeae49b
 The evidence is typically represented by many
Slide 45
Evaluation of Learning Model
least once (or a smaller value)
H1 0.7 0.2 0.1
 Example: predict if a customer is likely to purchase
log(P(hit|SPORTS)) + log(P(the| SPORTS))
)P(c ii 
conditional probabilities
3. Test set ~20%
 training set: 60,000 examples
 But… P(E)
the model identified as
 We cannot have a table with the probability of all
i
 Categorization: P(Category | Features of Object)
doc100000:  … stove…heat… ball…
 Two events A and B are independent:
 P(spots=yes) = 0.05
4. Measure performance with the validation set, and adjust hyper-
p(w1|c2) p(w2|c2) p(w3|c2) p(w4|c2) p(w5|c2) p(w6|c2)
 P is a probability function:
Types of ML Algorithms
 P(head, head) = 1/2 * 1/2 = 1/4
Naïve Bayes Algorithm
 so we can drop it
22.09/2)yesPlayTennis|sunnyOut(P
 100,000 docs in Cooking
c1: COOKING c2: SPORTS
e-mail Representation
iiii

Recall, Precision
 intersection A1 ∩ ...∩ An is an event that takes place if all the events
B)P(A  B)|P(A 
X6  X6  X6  X6 
A+B
Assume:
weather
Slide 8
 P(A, B |  C) = P(A | C) x P(B | C).
 P(referee|COOKING) =    P(referee|SPORTS) =
Slide 55
certain goods according to history of shopping
Combining Evidence
Over 2.5 quintillion bytes of data are created every single day, and it is only going to
38
54
 DO NOT LOOK AT THE TEST SET  until step 5.
→ Worksheet #3 (“Bayes’ Theorem”)
)H|P(a x )P(H argmax H
)H|strongP(Wind x )H|highP(Humidity x
// 1. training
)H|coolP(Temp x )H|sunnyP(Outlook x )P(H argmax
Today
1. Introduction to ML
→ Worksheet #3 (“Email Spam Detection”)
 ex: living in Montreal & tossing a coin
 If you have red spots on your face, you might have
instance
→ Worksheet #3 (“AI Weather Prediction”)
 select Hi such that P(Hi | E2) is the greatest
C are actually correct?
yes)P(Youngyes) eP(Toothach
 P(Montreal, head) = P(Montreal) * P(head)
 Assume:
the concept Machine Learning:
w1 w2 w3 w4 w5 w6
 We typically want to know: P(Hypothesis | Evidence)
Slide 48
Day5 Rain Cool Normal Weak Yes
00024.0
anyways!
are in class C
 The assumption of conditional independence, often does
known output
non-factual knowledge?
es
27
72
 How do we represent and reason about
 P(Disease | Symptoms)… P(meningitis | red spots)

a2
parameters* to improve performance
Day10 Rain Mild Normal Weak Yes
 Task: classify new digits into one
 ex: spam / ham
Slide 6
Slide 67
But since we only care about ranking the hypothesis…
Slide 42
P(Toothache ∩ Cavity)
spots?
49
a4
 e.g. Clustering, Anomaly Detection,
E)H P(E)|P(H 
 each e-mail is represented by a vector of feature/value:
Example 4
class C and that the model
features / evidence / X f(X)
 But P(Hypothesis| Evidence) is hard to gather
 union A1∪...∪ An is an event that takes place if at least one of the
 ex: add-1 smoothing:
~80%

 It might rain tonight
36.014/5)noPlayTennis(P
clouds
Slide 41
 data set contains handwritten
)yesPlayTennis(P )1
 ex: Medical Diagnosis
57
3. Evaluation
5. Measure performance with the test set
 P(spots=yes | meningitis=yes) = 0.4
th
1 )c in w of (frequency
Slide 3
Remember this slide…
X7  X7  X7  X7 
Precision =
obtained
X3  X3  X3  X3 
 Joint probability
63
on unlabeled data
 we can do probabilistic inference
24
→ Worksheet #3 (“AI Fraud Detection”)
34
 compute the probabilities from the training set
for all words wj in the vocabulary
 Precision: What proportion of instances labeled with the class
 and:
20
NB
doc4:   "cheap book sale, not meds"
 …
Slide 14
yes yes ?
 Character recognition: P(character | bitmap)
An agent interacts with its
a) For each hypothesis Hi
doc1:   … ball… heat…
Slide 60
X6  X6 
9
 Times, the probability that B occurs, assuming that A occurred
60.05/3)noPlayTennis|strongWind(P
evidence  hypothesis
Slide 26
33

A B
47
)c in w of (frequency
… …
Slide 13
yes)spots|yesisP(meningit
 Accuracy
