
of each movie vector, which is defined as ||~m|| =
action 50,000
N∑
Use 4 significant digits for this table (protip: the length of each movie vector must now be 1).
for the three recommender systems (for k = 1, 2, 3):
Joe 0 1 0 1 0 1
Worksheet #5: Recommender Systems
Action Comedy Sci-Fi Horror Drama Romance length
Compute the length of each user vector and normalize it like before:
system 2 0 1 0
system 2
Jane
precision =
precision@k ·rel(k). Compute the AP@3 and
Task 4. Now we want to personalize the recommendations. We collected the following profiles about the
Task 8. Moving on to the average precision, AP @N = 1
1 2 3 1 2 3 AP@3
remaining 495 instances are not relevant for the user. A checkmark indicates that a system recommended
Evaluate the performance of the three systems using the measures Precision and Recall :
(assume N = 10,000,000) and tf-idf = (1 + log tft,d)×idf.
romantic 10,000
COMP474/6741 Intelligent Systems (Winter 2022)
−−−−→
Joe
Task 5. Now we can answer the question which movie a user is interested in. Compute the cosine similarities
Task 6. Consider the results from three different recommender systems below: Here, X1–X5 are the items
add it to the table above. Here, assume m = 3 (i.e., there could have been 3 correct recommendations in the
Movie1 = 〈4, 8, 6, 3, 0, 0〉. Compute the length
comedy 10,000
c=1
Action Comedy Sci-Fi Horror Drama Romance
√
∑
Precision Recall
system 1
imi · ni:
k=1
which movie is interesting to (buy, watch) for a customer who (bought, watched) Movie 1?
this item to the user (the first Target column is the ground truth):
df
this time based on the content of an item (like a movie description).
vectors are normalized, this is simply their dot product: sim(~m,~n) = cos(~m,~n) = ~m · ~n =
system 3 0 0 1
This is the information we need for an item-to-item recommendation engine: Now we can answer the question,
Movie 1
Finally, compute the normalized vector ~q as before (in Tasks 1&2) from the tf-idf vector:
Task 3. We can now compute how similar the movies are, by computing their cosine similarity. Since the
t21 + . . . + t
Jane 1 2 1 1 1 0
m1
ti
movies watched (bought) by our users in the past:
Movie 1 1
·
Task 7. Now we’re looking at ranked results. Based on the output below, compute precision@k = 1
rel(k) precision@k
rel(c)
recall =
between the user vectors and the movie vectors:
#all correct recommendations
Movie 2
top-3). Note the difference in the AP@3 for the three systems!
Movie 1 Movie 2 Movie 3
system 3
#all system recommendations
That is, here each system got exactly one recommendation right, but in a different position.
n (rounded to two significant digits).
system 1 1 0 0
||~m|| :
in the tf values below. Then compute idf = log10
token tf df idf tf-idf qi
Movie 1 4 8 6 3 0 0
#correct system recommendations
Task 2. Now you can normalize the vectors, by dividing the raw count of each tag ti by the length
2
zombies 100,000
Movie 2 1
N
k
(movies, photos, songs, . . . ) that the systems should have recommended as relevant for a specific user. The
m
k∑
COMP474/6741 Worksheet: Recommender Systems Winter 2022
Movie 3 1 4 0 3 0 10
Movie 3 1
Movie 2 0 5 0 8 5 0
You can now use these vectors for (cosine) similarity calculations to find recommendations as before, but
Task 1. Let’s take some movies that have been #tagged (or categorized) as follows:
Movie 3
Task 9. Create a content vector for the movie description m1 =“A comedy with zombies.” Start by filling
So, each movie becomes a 6-dimensional vector of tags ti, e.g.,
