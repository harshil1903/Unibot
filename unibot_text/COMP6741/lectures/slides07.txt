
https://informationstrategyrsm.wordpress.com/2014/10/19/
Voltaire: “It is better to risk saving a guilty man than to condemn an innocent one.”
Abduction
Precision, recall etc. are defined slightly differently
Motivation
Example
7.17
Evaluation of a ML Model
Pros
Evaluation Methodology
Inductive Learning
cos(~q , ~d ) =
Parameters used to set up the ML
where n is the number of attributes (features)
ML Types
Classification with kNN
7.18
3 When all data points have been assigned, recalculate the positions of the k
• Conclusion about all members of a class from the examination of only a few
• a possible metric is the
Learning Curve
• Given two vectors, we can compute a similarity coefficient between them
that are particular to the training data
British series House of Cards based on an analysis of its customers’ data
Introduction
Euclidian Distance
• There is no way to fit a linear
Deduction
Automated Reasoning
7.44
• for DTs: pruning level
https://medium.com/machine-learning-for-humans/neural-networks-deep-learning-cdad8aeae49b
7.52
function f(X) where f(X) is the desired output
7.61
• t number of iterations
7.39
7.2
Organize large, unstructured document collections:
• User defines k , the number of clusters
kNN Classification
O’Reilly, 2012.
• e.g., Naïve Bayes Classifier
2 Abduction
• % of instances of the test set the algorithm correctly classifies
• a.k.a. Undertraining
7.14
(so-called lazy learning)
• Some relevant attributes are not taken into account in the data set
at tasks in T, as measured by P, improves with
Induction
Application Example
• but after a while, not much improvement. . .
• Validation set (20%)
7.4
Metrics
• Paradise Papers (13.4 million confidential papers regarding offshore
Positive True Positive (TP) False Positive (FP)
• Each attribute has a fixed, finite number of possible values
3 Induction
2 All CS students on vacation are smart.
possibly with different methods
Copyright 2017 by O’Reilly Media, Inc., [MG17]
k-Means Clustering
• We construct a general explanation based on specific cases
What are Clusters?
7.41
• Remember, we do not “classify” documents (like in “spam vs. ham”)
• Simple, easy to understand and implement
• Some values of features are incorrect or missing (ex. errors in the data
→ Worksheet #6: Task 3
Required
big-data-analytics-house-of-cards-and-future-of-television-creation-consumption/
Partition data points to closest centroïds
Standard Methodology
https://commons.wikimedia.org/wiki/File:KnnClassification.svg
• From A∧C⇒ B and A∧D⇒ B, we conclude A⇒B
• n number of data points
Forecasting or predicting a value: e.g., house price, movie rating, temperature at noon, ...
Netflix: Predict Success of Original Content
• Most work in ML
enough features)
1 All CS students in COMP 474 are smart.
https://www.thestar.com/news/paradise-papers/2019/01/29/
• Combined Precision & Recall (harmonic mean)
7.42
Supplemental
• train on 9 of these, test on the 10th
7.26
• Split data into training (80%) and testing (20%) sets
Clustering Documents
7.40
i=1 qi · di√∑|v|
7.3
• We conclude from the general case to a specific example of the general case
• for NB: prior & conditional
k-fold Cross-Validation
→ Worksheet #6: Task 2
Euclidean distance
Alike 4.0 International license, https://creativecommons.org/licenses/by- sa/4.0/legalcode
Process of deriving new facts from a set of premises
7.34
Some Machine Learning Techniques
History
member of the class.
• Generally, there is no right or wrong answer to what the clusters in a dataset
7.60
• Example:
meaningless regularities in the data
Important realization: not all errors are created equal!
• Find the nearest existing data point to a new sample as before
k-Nearest-Neighbor (kNN) Classification
4 Machine Learning Evaluation
• repeat 10 times, resulting in 10 different performance results
Model predicts. . .
• when one class is more important than the others
• [PS12, Chapter 8] (Testing and Evaluation)
• Often used as a first exploratory step in data analysis
http://www.cognub.com/index.php/cognitive-platform/
• Find a function f that fits the training set well
https://www.youtube.com/watch?v=5I3Ei69I40s
• there is never enough training data
Reinforcement Learning
Positive Negative
7.49
DO NOT LOOK AT THE TEST SET
This is a so-called (binary) confusion matrix
value. Resulting class is decided by majority vote.
model, e.g.:
7.62
• Comparing different clustering algorithms is a difficult task:
Repeat until clusters stabilize
https://creativecommons.org/licenses/by-sa/3.0/legalcode
2 Divide collection into training, validation and test set
i=1 d i
Commonly used
• Training error is low
Inference
• Conclusion follows necessary from the premises.
• Not sound. . . but may be most likely explanation for B
Clustering Techniques
• So that given a new X , you can predict its f (X ) value
features are there, we may find
https://www.youtube.com/watch?v=X9ZES-fsxgU
Error Analysis
Inquiry, . . .
In 2013, Netflix decided to commission two seasons of the U.S. remake of the
Watch out for:
T and performance measure P if its performance
• Use a confusion matrix (contingency table)
Common issues
Evaluation Metrics
Machine Learning
7.24https://opensemanticsearch.org
Inductive Reasoning
https://commons.wikimedia.org/wiki/File:Overfitting.svg
• Converges very fast
2 Socrates is a man.
https://www.thestar.com/news/paradise-papers/2019/01/29/canada-revenue-agency-launches-100-audits-after-paradise-papers-leak.html
No one knows the correct clusters!
• [MG17, Chapters 2, 3, 5] (kNN, k-Means, Evaluation)
• Depending on ML algorithm, the training set can be further split into:
for:
Cross-Validation
https://www.youtube.com/watch?v=VMp6pq6_QjI
7.12
“dissimilar” to data items in other clusters.
Mind the evaluation task
• Recall = TP/(TP + FN)
Feature Vectors
Machine Learning for Intelligent Systems
1 Drunk people do not walk straight.
https://creativecommons.org/licenses/by-sa/4.0/legalcode
Supervised Learning
• Distance can be computed with different metrics, e.g.,
COMP 474/6741, Winter 2022
7.16
k-Means: Sensitivity to Initial Seeds
are.
→ Worksheet #6: Task 4
Parameters
Machine Learning Categories
7.19
Error Analysis
Example (1/5)
• A mathematical model to portray an n-dimensional space
• for DTs: features to split
• for NB: value of delta for
but irrelevant to the problem.
Commons Attribution-Share Alike 4.0 International license
Evaluation Metrics
Clustering Documents
• → for all k clusters, choose the one
documents)
7.38
smoothing
• Note: given n-dimensional vectors, we are using n − 1 dimensions for the similarity
5 Notes and Further Reading
• Given m vectors in an n-dimensional space, ~x1, . . . , ~xm ∈ Rn
7.45
3 Apply learning algorithm to training set to learn the parameters
investments)
probabilities
to its simplicity and efficiency
• Despite weaknesses, k-means is still one of the most popular algorithms, due
Re-assign data points to closest new centroïds
Some Words on Training. . .
1 Deduction
√∑|v|
(“convict the innocent!”)
https://opensemanticsearch.org
new data
• the more, the better
‘Re-use’ different parts of the training data for testing. E.g., 10-fold cross-validation:
• assign the same class as the majority of the k closest neighbors to the new
Department of Computer Science
training data at hand
7.31
∑|v|
aka Natural Deduction
Predictions
1 All men are mortal.
• Also called parallel distributed processing or connectionist systems
• when all classes are equally important and represented
Partition-based Clustering
7.7
canada-revenue-agency-launches-100-audits-after-paradise-papers-leak.html
• Guantanamo Bay Files, TPP Agreements, CIA Documents, German BND-NSA
Classification with kNN
• Use only discriminating features as questions in a big if-then-else tree
7.55
→ Worksheet #6: Task 5
too simple decision boundary
p = (p1,p2, . . . ,pn)
Confusion Matrix
Notes and Further Reading
7.47
2 Clustering Documents
General machine learning process
https://commons.wikimedia.org/wiki/File:Precisionrecall.svg
• Compute the distance of the unknown sample to all existing samples
• Assign the class of the closest neighbor to the new sample
• Cosine of the angle between two vectors reflects their degree of similarity
7.64
2
• False negative classification: Type II error
training examples are well separated
• From A⇒ B and B, we conclude A
• Each example can be interpreted as a point in a n-dimensional feature space,
7.15
• If a large number of irrelevant
• Intelligence arise from having a large number of simple computational units
7.33
• kNN classification becomes a voting algorithm
Inductive Learning Framework
7.10
• Input data are represented by a vector of features, X
Learning from examples
Primer
• for ANNs: weights
7.65
Motivation
7.11
https://concordiauniversity.on.worldcat.org/oclc/801812987.
7.6
• Wikileaks – often releases millions of documents
Methodology
• From A⇒ B and A, we conclude that B
• The number of attributes is fixed (positive, finite)
• Actual training set (80%)
• Rather, we group similar documents together
• Accuracy = (TP + TN)/(TP + TN + FP + FN)
d =
• Luanda Leaks (715,000 emails, charts, contracts, audits, etc.)
7.68
• Entities are described by vectors with n coordinates in a real space Rn
• Choice of k is dependent on data set
7.8
Copyright by Chabacano (https://commons.wikimedia.org/wiki/File:Overfitting.svg) license under the Creative Commons Attribution-Share
7.46
Concordia University
Note: in this simple form, kNN has no training effort, but large testing effort
Regression with kNN
• But, can be seen as hypothesis construction or generalisation
until you arrived at Step 6.
7.22
Recall & Precision
3 from 1 ∧ 2 ⇒ Socrates is mortal.
• Not sound
Training: only store feature vectors + class labels
Example (4/5)
• You run your classifier on a data set of unseen examples (that you did not use
• The organization of unlabeled data into similarity groups, called clusters
(pi − qi )2
• False positive classification: Type I error
data (a.k.a. overtraining)
→ Worksheet #6: Task 1
Example: Animal Classification
7.53
• Extreme case: “rote learning”
• Each vector X is a list of (attribute, value) pairs.
Cross-Validation
https://concordiauniversity.on.worldcat.org/oclc/960211579.
2 patient complains about some symptoms. . . doctor concludes a disease
where ~x has the smallest distance
• Used in medicine. . .
Evaluation of Classifiers
7.51
AI, ML, DL
https://www.youtube.com/watch?v=85fZcK5EpnA
idf = log
Classification Algorithms
4 Repeat Steps 2 and 3 until none of the data instances change group
Machine Learning Evaluation
improve performance
Data Scarcity
F-Measure
Features
• Noisy Data
NB: Deep Learning ≈ Neural Networks “on steroids”
k-Means: Pros & Cons
Introduction to Machine Learning with Python.
Types of logical inference
In 1959, Arthur Samuel first proposed the concept
Decision Trees
• Our subclass inference in RDFS also falls into this category.
decision boundary so that the
References
licensed under https://creativecommons.org/licenses/by- sa/3.0/legalcode
• Information extraction tasks
• Extrapolate from the training set to make accurate predictions about future
Plot evaluation metric vs. size of training set
Process
• Testing error is high
Natural Language Annotation for Machine Learning.
Regression
• We can also underfit data, i.e. use
k-Means & Outliers
3 Classifications & Predictions
• they are too tuned to the particular
2 Assign each data point ~xi to the nearest centroïd.
experience E with respect to some class of tasks
sample
→ considered linear for practical purposes
Learn from experience
Overfitting
centroïds as the average of the cluster.
1 in reality: disease⇒ symptoms
With k = 1
AI Learns to Park
√√√√ n∑
Classifications &
Outline
Lecture 7
• Examples are given (positive and/or negative) to train a system in a
Labeled Data
kNN Regression
Underfitting
7.57
From datascience.com, https://towardsdatascience.com/cat- dog- or- elon- musk- 145658489730
7.23
[MG17] Andreas C Müller and Sarah Guido.
Cons
(2)
7.37
(3)
[PS12] James Pustejovsky and Amber Stubbs.
guidance from an expected output.
Abductive Reasoning
Notes and Further
1 Pick k points from the dataset (usually at random).
To find the nearest centroïd:
Negative False Negative (FN) True Negative (TN)
Euclidean distance or Manhattan distance
Compute new centroïds
• split data into 10 equal parts
• Different results on same dataset, based on initial (random) centroïds
Evaluation
These points represent our initial group centroïds.
7.54
Note: choosing one function over another beyond just looking at the training set is
What kind of errors can we make?
dft
• Given a new instance X you have never seen, you must find an estimate of the
• Note that this algorithm cannot extrapolate
In Unsupervised Learning, we have only unlabeled data and train a system without
In Supervised Learning, we train a system using data with known labels.
7.13
O’Reilly, 2017.
René Witte
[from: Alison Cawsey: The Essence of AI (1997)]
• where to assign a data point ~x?
Clustering
• so testing data is precious as well
• distance d between 2 points p, q
7.50
https://creativecommons.org/licenses/by- sa/4.0/legalcode
(“free the guilty!”)
and the final for the predicted value
Machine Learning Primer
Reading Material
• Data points (here: documents) in individual clusters can be further analyzed,
7.67
7.20
examples
Find the k nearest existing data points
Copyright 2007–2019, scikit-learn developers (BSD License), https://scikit- learn.org/stable/auto_examples/model_selection/plot_learning_curve.html
Machine Learning at Netflix
Introduction
• Classification tasks
kNN Regression: General Case
Probabilistic Methods
7.66
5 Performance not good enough? ⇒ 3
• How do you know if what you learned is correct?
• Efficient: Time complexity O(t · k · n), with
• Sensitive to outliers
Document Clustering Example: Analyzing NSF Research Grants
kNN Algorithm
Unlabeled Data
4 Measure performance with the validation set, and adjust hyper-parameters to
3 from 1 ∧ 2 ⇒ All CS students are smart.
7.28
Intro to ML
• Ranked retrieval tasks
https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html
Classifications & Predictions
Machine Learning:
• for ANNs: # of hidden layers, # of
• They do not generalize well to the
acquisition)
Application Example
Accuracy
• [PS12, Chapter 7] (ML Training)
• Facebook internal documents leaks (Cambridge Analytica scandal, 7000
• No clear evidence that any other clustering algorithm performs better in general
experience E.”
3 from 1 ∧ 2 ⇒ John is drunk.
Math with Words
Assign the average of their values to the new point
• Ex: X =[nose:big, teeth:big, eyes:big, moustache:no]
7.1
Intelligent Systems for Investigative Journalism
for training) for which you know the correct classification (“gold standard”)
Neural Networks
Training vs. testing data
Evaluation Methodology
• Complicated boundaries overfit the
With arbitrary k
7.58
Noisy Data
ML Types
7.59
Example (3/5)
https://concordiauniversity.on.worldcat.org/oclc/960211579
and Software Engineering
https://informationstrategyrsm.wordpress.com/2014/10/19/big-data-analytics-house-of-cards-and-future-of-television-creation-consumption/
k-Means
7.35
• Information retrieval tasks
Process
• Given pairs (X , f (X )) (the training set – the data points)
https://towardsdatascience.com/cat-dog-or-elon-musk-145658489730
• Assign the value of this point (e.g., price, rating, ...) to the new instance
Hyper-Parameters
q = (q1,q2, . . . ,qn)
Regression with kNN
i=1
7.9
• Precision = TP/(TP + FP)
kNN Classification: General case
1 Collect a large set of examples (all with correct classifications)
Overfitting
Example (5/5)
1 Machine Learning Primer
7.63
Testing: Find the k data points nearest (e.g., Euclidian distance) to the new
Basic values learned by the ML
7.21
• User needs to choose k (usually not known)
i=1 q i
7.27
• average these for overall performance
Vector Space Model
Summary
• Overfitting/Underfitting
Unsupervised Learning
Algorithm
Error Types
Introduction, Clustering, Classification, Regression, Evaluation
• A cluster is a collection of data items which are “similar” between them, and
• Model is not expressive enough (not
7.48
7.25
k-Means Clustering Illustrated
tf = 1 + log(tft,d ) (1)
• Two examples have the same feature-value pairs, but different outputs
2 John does not walk straight.
7.30
called inductive bias (eg. prefer “smoother” functions)
2 ·
classification (or regression) task
Reading
Copyright Antti Ajanki (https://commons.wikimedia.org/wiki/File:KnnClassification.svg), “KnnClassification”,
History
7.43
7.36
Underfitting
N
• Training error is high
ML Evaluation
Reality says. . .
Example (2/5)
6 Measure performance with the test set
• Conclusion is one hypothetical (most probable) explanation for the premises
7.29
(or changes stay below a given convergence limit ∆).
• F1-score = 2·Precision·RecallPrecision+Recall (harmonic mean)
7.56
nodes per layer. . .
“A computer program is said to learn from
k-Means Clustering
What about cat vs. dog?
2D-vectors, k=3: Initialize random centroïds
• Where did the learner go wrong ?
Classification of Data
K-means (MacQueen, 1967) is a partitional clustering algorithm:
Copyright by Walber (https://commons.wikimedia.org/wiki/File:Precisionrecall.svg), licensed under the Creative
• k number of clusters
7.32
• Enron email dataset – ca. 500,000 emails from management
7.5
https://concordiauniversity.on.worldcat.org/oclc/801812987
